{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for precursors calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_avg(sonde_file, parameters, windowsize=15, count_err=False):\n",
    "    \"\"\"\n",
    "      Функция читает переданный в sonde_file файл с показаниями ионозонда\n",
    "    и производит подсчет скользящего среднего характеристик из списка parameters\n",
    "    с окном размера windowsize. Опция count_err добавляет подсчет среднего\n",
    "    значения ошибки показаний (если показания были восстановлены интерполяцией).\n",
    "    \"\"\"\n",
    "    t = pd.read_csv(sonde_file, sep='\\t')\n",
    "    err_features = []\n",
    "    if count_err:\n",
    "        err_features = list(filter(lambda x: x.endswith('_err'), t.columns.values))\n",
    "    t = t[['sonde', 'year', 'date', 'h', 'm'] + parameters + err_features]\n",
    "    t = t.sort_values(by=['date', 'h', 'm'])\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    for h, m in t[['h', 'm']].drop_duplicates().values: \n",
    "        t_subset = t.loc[(t.h == h) & (t.m == m)]\n",
    "        ra = t_subset[parameters + err_features].rolling(15, min_periods=1).mean().shift(1)\n",
    "        nd = t_subset[parameters].rolling(15, min_periods=1).count().shift(1)\n",
    "        \n",
    "        ra.rename(index=int,\n",
    "                  columns=dict(zip(parameters + err_features,\n",
    "                                   [p + '_running_avg' for p in (parameters + err_features)])),\n",
    "                  inplace=True)\n",
    "        nd.rename(index=int,\n",
    "                  columns=dict(zip(parameters, [p + '_n_days' for p in parameters])),\n",
    "                  inplace=True)\n",
    "        \n",
    "        res = pd.concat([res, t_subset.join(ra).join(nd)])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonde_subset(sonde, parameters, dates, range_):\n",
    "    subset = pd.DataFrame()\n",
    "    \n",
    "    sonde['date'] = sonde['date']\\\n",
    "                   .apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "        \n",
    "    if range_ == 'all':\n",
    "        return sonde[['sonde', 'year', 'date', 'h', 'm'] + parameters]\n",
    "        \n",
    "    min_date = sonde['date'].min()\n",
    "    sonde['day_temp'] = sonde['date'].apply(lambda x: (x - min_date).days)\n",
    "    \n",
    "    for date in dates:\n",
    "        day = (date - min_date).days\n",
    "        subset = pd.concat([subset,\n",
    "                           sonde.loc[(sonde.day_temp - day >= range_[0]) \n",
    "                                    & (sonde.day_temp - day <= range_[1])][\n",
    "                               ['sonde', 'year', 'date', 'h', 'm'] + parameters]\n",
    "                           ])\n",
    "    return subset\n",
    "\n",
    "\n",
    "def correlation(sonde_file1, sonde_file2, parameters, earthquakes_dates, range_=[-10, 4]):\n",
    "    \"\"\"\n",
    "      Функция считает дневную корреляцию характеристик из списка\n",
    "    parameters для зондов, показания которых записаны в файлах\n",
    "    sonde_file1 и sonde_file2. Корреляция считается для временных \n",
    "    интервалов (d + range_[0], d + range_[1]) для каждой даты d из\n",
    "    earthquakes_dates, если range_ задан двумя числами, или для \n",
    "    всех возможных дней, если range_=='all'.\n",
    "    \"\"\"\n",
    "    s1 = pd.read_csv(sonde_file1, sep='\\t')\n",
    "    s2 = pd.read_csv(sonde_file2, sep='\\t')\n",
    "    \n",
    "    earthquakes_dates = [datetime.datetime.strptime(d, '%Y-%m-%d') \n",
    "                         for d in earthquakes_dates]\n",
    "    \n",
    "    s1 = sonde_subset(s1, parameters, earthquakes_dates, range_)\n",
    "    s2 = sonde_subset(s2, parameters, earthquakes_dates, range_)\n",
    "\n",
    "    s1.rename(index=int,\n",
    "             columns=dict(zip(['sonde'] + parameters, \n",
    "                              ['sonde1'] + [p + '1' for p in parameters])),\n",
    "             inplace=True)\n",
    "    s2.rename(index=int,\n",
    "             columns=dict(zip(['sonde'] + parameters, \n",
    "                              ['sonde2'] + [p + '2' for p in parameters])),\n",
    "             inplace=True)\n",
    "    \n",
    "    merged = pd.merge(s1, s2, how='inner', on=['year', 'date', 'h', 'm'])\n",
    "    res = pd.DataFrame()\n",
    "    row = {\n",
    "            'sonde1': merged.sonde1.values[0],\n",
    "            'sonde2': merged.sonde2.values[0],\n",
    "        }\n",
    "    \n",
    "    for d, y in merged[['date', 'year']].drop_duplicates().values:\n",
    "        row['date'] = d\n",
    "        row['year'] = int(y)\n",
    "        subset = merged.loc[merged.date == d]\n",
    "        for p in parameters:\n",
    "            row[p + '_corr'] = subset[p+'1'].corr(subset[p+'2'], min_periods=2)\n",
    "            row[p + '_n_hours'] = subset[['h', p+'1', p+'2']].dropna().h.nunique()\n",
    "            row[p + '_total_time_points'] = subset[['h', p+'1', p+'2']].dropna().shape[0]\n",
    "            \n",
    "        res = res.append(row, ignore_index=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_comparison(eq, in_, out_, parameters):\n",
    "    \"\"\"\n",
    "      Функция для указанного в eq землетрясения \n",
    "    создает таблицу, состоящую из показателей parameters\n",
    "    для группы зондов внутри зоны подготовки землетрясения\n",
    "    (из таблицы in_) и снаружи (из таблицы out_). \n",
    "    \"\"\"\n",
    "    s1, s1_sondes = merge_sondes(in_, eq, in_, parameters)\n",
    "    s2, s2_sondes = merge_sondes(out_, eq, in_, parameters)\n",
    "    date = in_[in_.earthquake_id == eq].date.values[0] \n",
    "    \n",
    "    if len(s1_sondes) < 2 or len(s2_sondes) < 2:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    s1 = label_group(s1, date, 's1', parameters)\n",
    "    s2 = label_group(s2, date, 's2', parameters)\n",
    "    \n",
    "    ds = pd.merge(s1, s2, how='inner', on=['date', 'h', 'm'])\n",
    "    ds['lbl'] = ds.apply(lambda x: 'pre_eq' if x['lbl_x'] == 'pre_eq' or x['lbl_y'] == 'pre_eq' \\\n",
    "                        else 'not_eq', axis=1)\n",
    "    ds.drop(columns=['lbl_x', 'lbl_y'], inplace=True)\n",
    "    ds['deviation'] = (ds.foF2_avg_s1 - ds.foF2_avg_s2).abs()\n",
    "    return ds\n",
    "\n",
    "def merge_sondes(ds, eq, in_, parameters):\n",
    "    s = pd.DataFrame()\n",
    "    s_sondes = []\n",
    "\n",
    "    for sonde in ds[ds.earthquake_id==eq].sonde.values:\n",
    "        t = pd.read_csv(f'../NCEI_dataset/ionosondes_data_corrected/{sonde}_corrected.csv',\n",
    "                               sep='\\t', parse_dates=['date'])\n",
    "        s_sondes.append(sonde)\n",
    "        \n",
    "        t = t[['date', 'h', 'm'] + parameters]\n",
    "        t.rename(columns=dict(zip(parameters, \n",
    "                                 [p+sonde for p in parameters])), \n",
    "                 inplace=True)\n",
    "        \n",
    "        t = remove_pre_eq_days(t, in_[(in_.sonde == sonde) \n",
    "                                      & (in_.earthquake_id != eq)].date.values)\n",
    "        \n",
    "        if s.shape[0] == 0:\n",
    "            s = t.copy()\n",
    "        else:\n",
    "            s = pd.merge(s, t, how='outer', on=['date', 'h', 'm'])\n",
    "\n",
    "    for p in parameters:\n",
    "        columns = list(filter(lambda x: x.startswith(p), s.columns.values))\n",
    "        s[p+'_avg'] = s[columns].apply(np.nanmean, axis=1)\n",
    "        s[p+'_n_sondes'] = (~s[columns].isnull()).sum(axis=1)\n",
    "\n",
    "    return s, s_sondes\n",
    "\n",
    "def remove_pre_eq_days(df, dates):\n",
    "    if len(dates) == 0:\n",
    "        return df\n",
    "    min_date = min(dates)\n",
    "    dates_num = [(d - min_date).astype('timedelta64[D]') / np.timedelta64(1, 'D')\n",
    "                 for d in dates]\n",
    "    df['temp_day_numb'] = df.date.apply(lambda x: (x - min_date).days)\n",
    "    \n",
    "    for n in dates_num:\n",
    "        df = df[df.temp_day_numb.apply(lambda x: x < n - 10 or x > n - 4)]\n",
    "        \n",
    "    return df.drop(columns=['temp_day_numb'])\n",
    "\n",
    "def label_group(ds, date, name, parameters):\n",
    "    ds['lbl'] = 'not_eq'\n",
    "    ds.loc[ds.date.apply(lambda x: ((x - date).days >= -7) and ((x - date).days <= 0)),\n",
    "          'lbl'] = 'pre_eq'\n",
    "\n",
    "    for p in parameters:\n",
    "        ds.rename(columns={p+'_avg': p+'_avg_'+name,\n",
    "                           p+'_n_sondes': p+'_n_sondes_'+name}, \n",
    "                     inplace=True)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt139 = running_avg('../NCEI_dataset/ionosondes_data_corrected/VT139_corrected.csv', ['foF2'],\n",
    "                   count_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sonde</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>h</th>\n",
       "      <th>m</th>\n",
       "      <th>foF2</th>\n",
       "      <th>foF2_err</th>\n",
       "      <th>foF2_running_avg</th>\n",
       "      <th>foF2_err_running_avg</th>\n",
       "      <th>foF2_n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VT139</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VT139</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>VT139</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>VT139</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>VT139</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-07-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sonde  year        date  h  m  foF2  foF2_err  foF2_running_avg  \\\n",
       "0    VT139  1999  1999-06-28  0  0  7.75       0.0               NaN   \n",
       "96   VT139  1999  1999-06-29  0  0  7.45       0.0              7.75   \n",
       "192  VT139  1999  1999-06-30  0  0  8.35       0.0              7.60   \n",
       "288  VT139  1999  1999-07-01  0  0  8.85       0.0              7.85   \n",
       "384  VT139  1999  1999-07-02  0  0  9.35       0.0              8.10   \n",
       "\n",
       "     foF2_err_running_avg  foF2_n_days  \n",
       "0                     NaN          NaN  \n",
       "96                    0.0          1.0  \n",
       "192                   0.0          2.0  \n",
       "288                   0.0          3.0  \n",
       "384                   0.0          4.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt139.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_vs_ra = correlation('../NCEI_dataset/ionosondes_data/VT139.csv', \n",
    "                       '../NCEI_dataset/ionosondes_data/RA041.csv',\n",
    "                      ['foF2'], ['2019-09-21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>foF2_corr</th>\n",
       "      <th>foF2_n_hours</th>\n",
       "      <th>foF2_total_time_points</th>\n",
       "      <th>sonde1</th>\n",
       "      <th>sonde2</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>0.960367</td>\n",
       "      <td>24.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>0.968764</td>\n",
       "      <td>23.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>0.936932</td>\n",
       "      <td>22.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>0.960135</td>\n",
       "      <td>21.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>0.936880</td>\n",
       "      <td>23.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>0.920758</td>\n",
       "      <td>22.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>0.942272</td>\n",
       "      <td>24.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>0.974411</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>0.978056</td>\n",
       "      <td>20.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.949523</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>VT139</td>\n",
       "      <td>RA041</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  foF2_corr  foF2_n_hours  foF2_total_time_points sonde1 sonde2  \\\n",
       "0 2019-09-11   0.960367          24.0                    80.0  VT139  RA041   \n",
       "1 2019-09-12   0.968764          23.0                    87.0  VT139  RA041   \n",
       "2 2019-09-13   0.936932          22.0                    68.0  VT139  RA041   \n",
       "3 2019-09-14   0.960135          21.0                    74.0  VT139  RA041   \n",
       "4 2019-09-15   0.936880          23.0                    76.0  VT139  RA041   \n",
       "5 2019-09-16   0.920758          22.0                    67.0  VT139  RA041   \n",
       "6 2019-09-17   0.942272          24.0                    91.0  VT139  RA041   \n",
       "7 2019-09-18   0.974411          23.0                    80.0  VT139  RA041   \n",
       "8 2019-09-19   0.978056          20.0                    66.0  VT139  RA041   \n",
       "9 2019-09-20   0.949523          22.0                    80.0  VT139  RA041   \n",
       "\n",
       "     year  \n",
       "0  2019.0  \n",
       "1  2019.0  \n",
       "2  2019.0  \n",
       "3  2019.0  \n",
       "4  2019.0  \n",
       "5  2019.0  \n",
       "6  2019.0  \n",
       "7  2019.0  \n",
       "8  2019.0  \n",
       "9  2019.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt_vs_ra.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ = pd.read_csv('../USGS_dataset/sondes_in_eq_prep_zone.csv', sep='\\t',\n",
    "                 parse_dates=['date'])\n",
    "out_ = pd.read_csv('../USGS_dataset/sondes_out_eq_prep_zone.csv', sep='\\t',\n",
    "                 parse_dates=['date'])\n",
    "s1s2 = groups_comparison('usp000h2gd', in_, out_, ['foF2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>h</th>\n",
       "      <th>m</th>\n",
       "      <th>foF2BR52P</th>\n",
       "      <th>foF2NI63_</th>\n",
       "      <th>foF2TV51R</th>\n",
       "      <th>foF2_avg_s1</th>\n",
       "      <th>foF2_n_sondes_s1</th>\n",
       "      <th>foF2DW41K</th>\n",
       "      <th>foF2KJ609</th>\n",
       "      <th>...</th>\n",
       "      <th>foF2VA50L</th>\n",
       "      <th>foF2CN53L</th>\n",
       "      <th>foF2PY52R</th>\n",
       "      <th>foF2GH64L</th>\n",
       "      <th>foF2HO54K</th>\n",
       "      <th>foF2CB53N</th>\n",
       "      <th>foF2_avg_s2</th>\n",
       "      <th>foF2_n_sondes_s2</th>\n",
       "      <th>lbl</th>\n",
       "      <th>deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.988000</td>\n",
       "      <td>8.39100</td>\n",
       "      <td>8.917667</td>\n",
       "      <td>8.432222</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.99745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.35800</td>\n",
       "      <td>8.34300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.899483</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>0.532739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8.106375</td>\n",
       "      <td>8.65200</td>\n",
       "      <td>9.160583</td>\n",
       "      <td>8.639653</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.09520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.43300</td>\n",
       "      <td>8.24850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.925567</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>0.714086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8.224750</td>\n",
       "      <td>8.91300</td>\n",
       "      <td>9.403500</td>\n",
       "      <td>8.847083</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.19295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.50800</td>\n",
       "      <td>8.15400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.951650</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>0.895433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>8.343125</td>\n",
       "      <td>9.17400</td>\n",
       "      <td>9.646417</td>\n",
       "      <td>9.054514</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.29070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.58300</td>\n",
       "      <td>8.05950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.977733</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>1.076781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.461500</td>\n",
       "      <td>9.43500</td>\n",
       "      <td>9.889333</td>\n",
       "      <td>9.261944</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.38845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.65800</td>\n",
       "      <td>7.96500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.003817</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>1.258128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8.579875</td>\n",
       "      <td>11.53225</td>\n",
       "      <td>10.132250</td>\n",
       "      <td>10.081458</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.49720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.61675</td>\n",
       "      <td>8.10725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.073733</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>2.007725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>8.698250</td>\n",
       "      <td>13.62950</td>\n",
       "      <td>10.375167</td>\n",
       "      <td>10.900972</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.60870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.57550</td>\n",
       "      <td>8.24950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.144567</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>2.756406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>8.816625</td>\n",
       "      <td>15.72675</td>\n",
       "      <td>10.618083</td>\n",
       "      <td>11.720486</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.72020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.53425</td>\n",
       "      <td>8.39175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.215400</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>3.505086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.935000</td>\n",
       "      <td>17.82400</td>\n",
       "      <td>10.861000</td>\n",
       "      <td>12.540000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.83170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.49300</td>\n",
       "      <td>8.53400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.286233</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>4.253767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9.093000</td>\n",
       "      <td>15.67850</td>\n",
       "      <td>10.848750</td>\n",
       "      <td>11.873417</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.90000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.46375</td>\n",
       "      <td>8.49900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.287583</td>\n",
       "      <td>3</td>\n",
       "      <td>not_eq</td>\n",
       "      <td>3.585833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  h   m  foF2BR52P  foF2NI63_  foF2TV51R  foF2_avg_s1  \\\n",
       "0 2004-11-03  0   0   7.988000    8.39100   8.917667     8.432222   \n",
       "1 2004-11-03  0  15   8.106375    8.65200   9.160583     8.639653   \n",
       "2 2004-11-03  0  30   8.224750    8.91300   9.403500     8.847083   \n",
       "3 2004-11-03  0  45   8.343125    9.17400   9.646417     9.054514   \n",
       "4 2004-11-03  1   0   8.461500    9.43500   9.889333     9.261944   \n",
       "5 2004-11-03  1  15   8.579875   11.53225  10.132250    10.081458   \n",
       "6 2004-11-03  1  30   8.698250   13.62950  10.375167    10.900972   \n",
       "7 2004-11-03  1  45   8.816625   15.72675  10.618083    11.720486   \n",
       "8 2004-11-03  2   0   8.935000   17.82400  10.861000    12.540000   \n",
       "9 2004-11-03  2  15   9.093000   15.67850  10.848750    11.873417   \n",
       "\n",
       "   foF2_n_sondes_s1  foF2DW41K  foF2KJ609  ...  foF2VA50L  foF2CN53L  \\\n",
       "0                 3        NaN        NaN  ...        NaN    7.99745   \n",
       "1                 3        NaN        NaN  ...        NaN    8.09520   \n",
       "2                 3        NaN        NaN  ...        NaN    8.19295   \n",
       "3                 3        NaN        NaN  ...        NaN    8.29070   \n",
       "4                 3        NaN        NaN  ...        NaN    8.38845   \n",
       "5                 3        NaN        NaN  ...        NaN    8.49720   \n",
       "6                 3        NaN        NaN  ...        NaN    8.60870   \n",
       "7                 3        NaN        NaN  ...        NaN    8.72020   \n",
       "8                 3        NaN        NaN  ...        NaN    8.83170   \n",
       "9                 3        NaN        NaN  ...        NaN    8.90000   \n",
       "\n",
       "   foF2PY52R  foF2GH64L  foF2HO54K  foF2CB53N  foF2_avg_s2  foF2_n_sondes_s2  \\\n",
       "0        NaN    7.35800    8.34300        NaN     7.899483                 3   \n",
       "1        NaN    7.43300    8.24850        NaN     7.925567                 3   \n",
       "2        NaN    7.50800    8.15400        NaN     7.951650                 3   \n",
       "3        NaN    7.58300    8.05950        NaN     7.977733                 3   \n",
       "4        NaN    7.65800    7.96500        NaN     8.003817                 3   \n",
       "5        NaN    7.61675    8.10725        NaN     8.073733                 3   \n",
       "6        NaN    7.57550    8.24950        NaN     8.144567                 3   \n",
       "7        NaN    7.53425    8.39175        NaN     8.215400                 3   \n",
       "8        NaN    7.49300    8.53400        NaN     8.286233                 3   \n",
       "9        NaN    7.46375    8.49900        NaN     8.287583                 3   \n",
       "\n",
       "      lbl  deviation  \n",
       "0  not_eq   0.532739  \n",
       "1  not_eq   0.714086  \n",
       "2  not_eq   0.895433  \n",
       "3  not_eq   1.076781  \n",
       "4  not_eq   1.258128  \n",
       "5  not_eq   2.007725  \n",
       "6  not_eq   2.756406  \n",
       "7  not_eq   3.505086  \n",
       "8  not_eq   4.253767  \n",
       "9  not_eq   3.585833  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1s2.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
